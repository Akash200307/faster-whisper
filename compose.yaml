version: '3.8'
services:
  whisper-asr:
    image: onerahmet/openai-whisper-asr-webservice:latest
    container_name: whisper-asr
    ports:
      - "9000:9000"  # Expose API on port 9000
    environment:
      - ASR_MODEL=base  # Options: tiny, base, small, medium, large (start with 'base' for balance)
      - ASR_ENGINE=openai_whisper  # Use official OpenAI engine
      - USE_CUDA=false  # Set to true if GPU available
    volumes:
      - ./cache:/root/.cache  # Persist model downloads to speed up restarts
    restart: unless-stopped